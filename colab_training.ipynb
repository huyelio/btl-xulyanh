{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c15605a",
   "metadata": {},
   "source": [
    "# ğŸš€ MNIST Model Training vá»›i Data Augmentation - Google Colab\n",
    "\n",
    "## ğŸ’¡ Má»¥c Ä‘Ã­ch\n",
    "Train MNIST model vá»›i **Data Augmentation** Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» **Domain Gap**.\n",
    "\n",
    "### âš ï¸ Váº¥n Ä‘á» Domain Gap:\n",
    "- **Model cÅ©**: Chá»‰ há»c trÃªn MNIST (áº£nh sáº¡ch, cÄƒn giá»¯a hoÃ n háº£o)\n",
    "- **áº¢nh thá»±c táº¿**: Bá»‹ lá»‡ch, xoay, zoom, nÃ©t má»ng, Ã¡nh sÃ¡ng khÃ´ng Ä‘á»u\n",
    "- **Káº¿t quáº£**: Model dá»± Ä‘oÃ¡n sai!\n",
    "\n",
    "### âœ… Giáº£i phÃ¡p:\n",
    "**Data Augmentation** - LÃ m \"báº©n\" áº£nh MNIST khi train:\n",
    "- Xoay ngáº«u nhiÃªn Â±15Â°\n",
    "- Dá»‹ch chuyá»ƒn ngáº«u nhiÃªn 15%\n",
    "- Zoom in/out ngáº«u nhiÃªn 15%\n",
    "- LÃ m mÃ©o áº£nh (shear)\n",
    "\n",
    "â†’ Model sáº½ \"khoan dung\" hÆ¡n vá»›i áº£nh viáº¿t tay thá»±c táº¿!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db717c",
   "metadata": {},
   "source": [
    "## ğŸ“¦ BÆ°á»›c 1: Kiá»ƒm tra GPU vÃ  Import thÆ° viá»‡n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiá»ƒm tra GPU\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"âœ… GPU Ä‘Æ°á»£c kÃ­ch hoáº¡t - Training sáº½ nhanh!\")\n",
    "else:\n",
    "    print(\"âš ï¸  Chá»‰ cÃ³ CPU - HÃ£y báº­t GPU: Runtime > Change runtime type > GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e083a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "print(\"âœ… Import thÃ nh cÃ´ng!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b773a92f",
   "metadata": {},
   "source": [
    "## ğŸ“¥ BÆ°á»›c 2: Load vÃ  Preprocess MNIST Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24078c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "print(\"ğŸ“¥ Äang táº£i MNIST dataset...\")\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Train shape: {x_train.shape}\")\n",
    "print(f\"Test shape: {x_test.shape}\")\n",
    "\n",
    "# Hiá»ƒn thá»‹ má»™t vÃ i máº«u\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(x_train[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle('MNIST Original Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "print(\"ğŸ”„ Preprocessing data...\")\n",
    "\n",
    "# Reshape vÃ  normalize vá» [0, 1]\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(f\"âœ… X_train: {x_train.shape}, Y_train: {y_train.shape}\")\n",
    "print(f\"âœ… X_test: {x_test.shape}, Y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d927c8f",
   "metadata": {},
   "source": [
    "## ğŸ¨ BÆ°á»›c 3: Táº¡o Data Augmentation Generator\n",
    "\n",
    "**ÄÃ‚Y LÃ€ PHáº¦N QUAN TRá»ŒNG NHáº¤T!** ğŸ”¥\n",
    "\n",
    "Data Augmentation sáº½ lÃ m cho áº£nh MNIST \"giá»‘ng\" áº£nh viáº¿t tay thá»±c táº¿ hÆ¡n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o Data Augmentation Generator\n",
    "print(\"ğŸ¨ Táº¡o Data Augmentation Generator...\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,       # Ngáº«u nhiÃªn xoay +/- 15 Ä‘á»™\n",
    "    width_shift_range=0.15,  # Ngáº«u nhiÃªn dá»‹ch ngang 15%\n",
    "    height_shift_range=0.15, # Ngáº«u nhiÃªn dá»‹ch dá»c 15%\n",
    "    zoom_range=0.15,         # Ngáº«u nhiÃªn phÃ³ng to/thu nhá» 15%\n",
    "    shear_range=0.1,         # Ngáº«u nhiÃªn lÃ m mÃ©o áº£nh (nghiÃªng)\n",
    "    fill_mode='constant',    # Fill pháº§n trá»‘ng báº±ng mÃ u Ä‘en (0)\n",
    "    cval=0\n",
    ")\n",
    "\n",
    "# Fit datagen vÃ o training data\n",
    "datagen.fit(x_train)\n",
    "\n",
    "print(\"âœ… Data Augmentation Generator ready!\")\n",
    "print(\"   â†’ Model sáº½ há»c tá»« áº£nh Ä‘Ã£ Ä‘Æ°á»£c 'lÃ m báº©n' (augmented)\")\n",
    "print(\"   â†’ Model sáº½ khoan dung hÆ¡n vá»›i áº£nh thá»±c táº¿!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8908b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Hiá»ƒn thá»‹ áº£nh gá»‘c vs áº£nh Ä‘Ã£ augmented\n",
    "print(\"ğŸ“Š Demo: So sÃ¡nh áº£nh gá»‘c vs áº£nh augmented\")\n",
    "\n",
    "# Láº¥y 1 áº£nh máº«u\n",
    "sample_img = x_train[0:1]  # Shape (1, 28, 28, 1)\n",
    "sample_label = np.argmax(y_train[0])\n",
    "\n",
    "# Táº¡o augmented images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "\n",
    "# HÃ ng 1: áº¢nh gá»‘c\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(sample_img[0].reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].set_title('Original')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# HÃ ng 2: áº¢nh augmented\n",
    "aug_iter = datagen.flow(sample_img, batch_size=1)\n",
    "for i in range(5):\n",
    "    aug_img = next(aug_iter)[0]\n",
    "    axes[1, i].imshow(aug_img.reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].set_title('Augmented')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle(f'Data Augmentation Demo (Label: {sample_label})', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ‘€ Quan sÃ¡t: áº¢nh augmented bá»‹ xoay, dá»‹ch, zoom, mÃ©o â†’ Giá»‘ng áº£nh thá»±c táº¿ hÆ¡n!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3820aa",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ BÆ°á»›c 4: Build CNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a356e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o CNN Model\n",
    "print(\"ğŸ—ï¸  Building CNN Model...\")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Input layer\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    \n",
    "    # Convolutional Block 1\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Convolutional Block 2\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Convolutional Block 3\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Fully Connected Layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Hiá»ƒn thá»‹ summary\n",
    "model.summary()\n",
    "\n",
    "print(\"\\nâœ… Model Ä‘Ã£ sáºµn sÃ ng!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962e35c",
   "metadata": {},
   "source": [
    "## ğŸ¯ BÆ°á»›c 5: Training vá»›i Data Augmentation\n",
    "\n",
    "**LÆ¯U Ã:**\n",
    "- TÄƒng `epochs` lÃªn **30** (thay vÃ¬ 15-20) vÃ¬ model pháº£i há»c bÃ i toÃ¡n khÃ³ hÆ¡n\n",
    "- Sá»­ dá»¥ng `datagen.flow()` thay vÃ¬ truyá»n trá»±c tiáº¿p `x_train`\n",
    "- Training time: ~15-20 phÃºt trÃªn GPU Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1eb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiáº¿t láº­p callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"âœ… Callbacks configured!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ TRAINING vá»›i Data Augmentation!\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ¯ Báº®T Äáº¦U TRAINING Vá»šI DATA AUGMENTATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"â° Æ¯á»›c tÃ­nh: 15-20 phÃºt trÃªn GPU Colab\")\n",
    "print(\"\")\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "history = model.fit(\n",
    "    # âš ï¸ QUAN TRá»ŒNG: Sá»­ dá»¥ng datagen.flow() thay vÃ¬ x_train trá»±c tiáº¿p\n",
    "    datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "    \n",
    "    epochs=EPOCHS,\n",
    "    \n",
    "    # Validation data KHÃ”NG augment (giá»¯ nguyÃªn)\n",
    "    validation_data=(x_test, y_test),\n",
    "    \n",
    "    # Sá»‘ steps má»—i epoch\n",
    "    steps_per_epoch=len(x_train) // BATCH_SIZE,\n",
    "    \n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… TRAINING HOÃ€N THÃ€NH!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad6a9a",
   "metadata": {},
   "source": [
    "## ğŸ“Š BÆ°á»›c 6: ÄÃ¡nh giÃ¡ vÃ  Visualize káº¿t quáº£\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trÃªn test set\n",
    "print(\"ğŸ“Š ÄÃ¡nh giÃ¡ model trÃªn test set...\")\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“ˆ Káº¾T QUáº¢ CUá»I CÃ™NG\")\n",
    "print(\"=\"*70)\n",
    "print(f\"âœ… Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"âœ… Test Loss: {test_loss:.4f}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8133f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "ax1.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy', fontsize=12)\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "ax2.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Loss', fontsize=12)\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Training History vá»›i Data Augmentation', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Training history plotted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb19011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions vá»›i má»™t vÃ i máº«u ngáº«u nhiÃªn\n",
    "print(\"ğŸ§ª Testing predictions trÃªn má»™t vÃ i máº«u ngáº«u nhiÃªn...\\n\")\n",
    "\n",
    "# Chá»n 10 áº£nh ngáº«u nhiÃªn\n",
    "indices = np.random.choice(len(x_test), 10, replace=False)\n",
    "sample_images = x_test[indices]\n",
    "sample_labels = y_test[indices]\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(sample_images, verbose=0)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    true_label = np.argmax(sample_labels[i])\n",
    "    pred_label = np.argmax(predictions[i])\n",
    "    confidence = predictions[i][pred_label] * 100\n",
    "    \n",
    "    # Hiá»ƒn thá»‹ áº£nh\n",
    "    axes[i].imshow(sample_images[i].reshape(28, 28), cmap='gray')\n",
    "    \n",
    "    # MÃ u xanh náº¿u Ä‘Ãºng, Ä‘á» náº¿u sai\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\\n({confidence:.1f}%)\", \n",
    "                      color=color, fontsize=10, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Predictions Test (Green=Correct, Red=Wrong)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# In ra accuracy\n",
    "correct = sum([np.argmax(sample_labels[i]) == np.argmax(predictions[i]) for i in range(10)])\n",
    "print(f\"\\nâœ… Accuracy trÃªn 10 máº«u: {correct}/10 ({correct*10}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b4dc36",
   "metadata": {},
   "source": [
    "## ğŸ’¾ BÆ°á»›c 7: LÆ°u Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5585289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LÆ°u model\n",
    "model_path = 'mnist_model_augmented.h5'\n",
    "model.save(model_path)\n",
    "\n",
    "print(f\"âœ… Model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {model_path}\")\n",
    "print(f\"ğŸ“¦ KÃ­ch thÆ°á»›c file: {os.path.getsize(model_path) / (1024*1024):.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d61fb5",
   "metadata": {},
   "source": [
    "## ğŸ“¥ BÆ°á»›c 8: Download Model vá» mÃ¡y Local\n",
    "\n",
    "**Cháº¡y cell bÃªn dÆ°á»›i Ä‘á»ƒ download model vá» mÃ¡y:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fd698",
   "metadata": {},
   "source": [
    "## ğŸ“¥ BÆ°á»›c 8: Download Model vá» mÃ¡y Local\n",
    "\n",
    "**Cháº¡y cell bÃªn dÆ°á»›i Ä‘á»ƒ download model vá» mÃ¡y:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model vá» mÃ¡y local\n",
    "from google.colab import files\n",
    "\n",
    "print(\"ğŸ“¥ Äang chuáº©n bá»‹ download model...\")\n",
    "files.download(model_path)\n",
    "print(\"âœ… Download hoÃ n táº¥t!\")\n",
    "print(\"\\nğŸ’¡ HÆ°á»›ng dáº«n:\")\n",
    "print(\"   1. File sáº½ Ä‘Æ°á»£c táº£i vá» thÆ° má»¥c Downloads\")\n",
    "print(\"   2. Di chuyá»ƒn file 'mnist_model_augmented.h5' vÃ o thÆ° má»¥c 'models/' cá»§a project\")\n",
    "print(\"   3. Äá»•i tÃªn thÃ nh 'mnist_model.h5' (hoáº·c update code app.py)\")\n",
    "print(\"   4. Cháº¡y láº¡i Streamlit app: streamlit run app.py\")\n",
    "print(\"   5. Enjoy! ğŸ‰\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74624a",
   "metadata": {},
   "source": [
    "## ğŸ‰ HOÃ€N THÃ€NH!\n",
    "\n",
    "### ğŸ“‹ TÃ³m táº¯t:\n",
    "- âœ… ÄÃ£ train model vá»›i **Data Augmentation**\n",
    "- âœ… Model Ä‘Ã£ há»c tá»« áº£nh bá»‹ xoay, dá»‹ch, zoom, mÃ©o\n",
    "- âœ… Model sáº½ **khoan dung hÆ¡n** vá»›i áº£nh viáº¿t tay thá»±c táº¿\n",
    "- âœ… ÄÃ£ lÆ°u vÃ  download model vá» mÃ¡y\n",
    "\n",
    "### ğŸš€ Tiáº¿p theo:\n",
    "1. Di chuyá»ƒn model vÃ o thÆ° má»¥c `models/` cá»§a project\n",
    "2. Cháº¡y Streamlit app: `streamlit run app.py`\n",
    "3. Test vá»›i áº£nh viáº¿t tay cá»§a báº¡n!\n",
    "\n",
    "### ğŸ’¡ Ká»³ vá»ng:\n",
    "- Accuracy trÃªn MNIST test set: **~99%**\n",
    "- Accuracy trÃªn áº£nh viáº¿t tay thá»±c táº¿: **TÄƒng Ä‘Ã¡ng ká»ƒ** so vá»›i model cÅ©!\n",
    "\n",
    "---\n",
    "\n",
    "**ChÃºc má»«ng báº¡n Ä‘Ã£ giáº£i quyáº¿t váº¥n Ä‘á» Domain Gap! ğŸŠ**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
