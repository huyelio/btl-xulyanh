# ğŸ”„ So sÃ¡nh Code: TrÆ°á»›c vs Sau Data Augmentation

## ğŸ“Š Train All - `train_all.py`

### âŒ TRÆ¯á»šC (Code cÅ©)

```python
# Load data
(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()

# Preprocess
x_train_mnist = x_train_mnist.reshape(-1, 28, 28, 1).astype('float32') / 255.0
x_test_mnist = x_test_mnist.reshape(-1, 28, 28, 1).astype('float32') / 255.0
y_train_mnist = keras.utils.to_categorical(y_train_mnist, 10)
y_test_mnist = keras.utils.to_categorical(y_test_mnist, 10)

# Train TRá»°C TIáº¾P (khÃ´ng augmentation)
history_mnist = mnist_model.fit(
    x_train_mnist, y_train_mnist,  # âŒ Truyá»n trá»±c tiáº¿p
    batch_size=128,
    epochs=20,  # âŒ Chá»‰ 20 epochs
    validation_data=(x_test_mnist, y_test_mnist),
    verbose=1
)
```

**Váº¥n Ä‘á»:**
- âŒ Model chá»‰ tháº¥y áº£nh gá»‘c, khÃ´ng cÃ³ biáº¿n thá»ƒ
- âŒ Há»c thuá»™c lÃ²ng MNIST, khÃ´ng tá»•ng quÃ¡t hÃ³a
- âŒ Fail trÃªn áº£nh thá»±c táº¿

---

### âœ… SAU (Code má»›i)

```python
# Load data
(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()

# Preprocess
x_train_mnist = x_train_mnist.reshape(-1, 28, 28, 1).astype('float32') / 255.0
x_test_mnist = x_test_mnist.reshape(-1, 28, 28, 1).astype('float32') / 255.0
y_train_mnist = keras.utils.to_categorical(y_train_mnist, 10)
y_test_mnist = keras.utils.to_categorical(y_test_mnist, 10)

# ğŸš€ DATA AUGMENTATION - Giáº£i phÃ¡p cho Domain Gap!
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=15,       # âœ… Xoay ngáº«u nhiÃªn
    width_shift_range=0.15,  # âœ… Dá»‹ch ngang
    height_shift_range=0.15, # âœ… Dá»‹ch dá»c
    zoom_range=0.15,         # âœ… Zoom in/out
    shear_range=0.1,         # âœ… LÃ m mÃ©o
    fill_mode='constant',
    cval=0
)

datagen.fit(x_train_mnist)

# Train vá»›i Data Augmentation
history_mnist = mnist_model.fit(
    datagen.flow(x_train_mnist, y_train_mnist, batch_size=128),  # âœ… DÃ¹ng generator
    epochs=30,  # âœ… TÄƒng lÃªn 30 epochs
    validation_data=(x_test_mnist, y_test_mnist),
    steps_per_epoch=len(x_train_mnist) // 128,  # âœ… ThÃªm steps_per_epoch
    verbose=1
)
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… Model tháº¥y nhiá»u biáº¿n thá»ƒ cá»§a má»—i áº£nh
- âœ… Há»c cÃ¡ch tá»•ng quÃ¡t hÃ³a, khÃ´ng thuá»™c lÃ²ng
- âœ… **Dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c trÃªn áº£nh thá»±c táº¿**

---

## ğŸ“Š Train MNIST - `src/train_mnist.py`

### âŒ TRÆ¯á»šC (Code cÅ©)

```python
def train_mnist_model(epochs=15, batch_size=128, save_dir='models'):
    """Huáº¥n luyá»‡n MNIST model"""
    
    # Load data
    (x_train, y_train), (x_test, y_test) = load_and_preprocess_mnist()
    
    # Táº¡o model
    model = create_mnist_model()
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    # Train TRá»°C TIáº¾P
    history = model.fit(
        x_train, y_train,  # âŒ Truyá»n trá»±c tiáº¿p
        batch_size=batch_size,
        epochs=epochs,  # âŒ Máº·c Ä‘á»‹nh 15 epochs
        validation_data=(x_test, y_test),
        callbacks=callbacks,
        verbose=1
    )
    
    return model, history
```

**Váº¥n Ä‘á»:**
- âŒ KhÃ´ng cÃ³ Data Augmentation
- âŒ Epochs tháº¥p (15)
- âŒ KhÃ´ng linh hoáº¡t (khÃ´ng thá»ƒ báº­t/táº¯t augmentation)

---

### âœ… SAU (Code má»›i)

```python
def train_mnist_model(epochs=30, batch_size=128, save_dir='models', use_augmentation=True):
    """Huáº¥n luyá»‡n MNIST model vá»›i Data Augmentation"""
    
    # Load data
    (x_train, y_train), (x_test, y_test) = load_and_preprocess_mnist()
    
    # ğŸš€ DATA AUGMENTATION
    if use_augmentation:
        from tensorflow.keras.preprocessing.image import ImageDataGenerator
        
        datagen = ImageDataGenerator(
            rotation_range=15,
            width_shift_range=0.15,
            height_shift_range=0.15,
            zoom_range=0.15,
            shear_range=0.1,
            fill_mode='constant',
            cval=0
        )
        datagen.fit(x_train)
    
    # Táº¡o model
    model = create_mnist_model()
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    # Train vá»›i hoáº·c khÃ´ng augmentation
    if use_augmentation:
        history = model.fit(
            datagen.flow(x_train, y_train, batch_size=batch_size),  # âœ… Generator
            epochs=epochs,  # âœ… Máº·c Ä‘á»‹nh 30 epochs
            validation_data=(x_test, y_test),
            steps_per_epoch=len(x_train) // batch_size,
            callbacks=callbacks,
            verbose=1
        )
    else:
        history = model.fit(
            x_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_data=(x_test, y_test),
            callbacks=callbacks,
            verbose=1
        )
    
    return model, history
```

**Æ¯u Ä‘iá»ƒm:**
- âœ… CÃ³ Data Augmentation
- âœ… Epochs cao hÆ¡n (30)
- âœ… Linh hoáº¡t: cÃ³ thá»ƒ báº­t/táº¯t augmentation
- âœ… Backward compatible

---

## ğŸ¯ Key Differences

| Feature | TrÆ°á»›c | Sau |
|---------|-------|-----|
| **Augmentation** | âŒ KhÃ´ng | âœ… CÃ³ (rotation, shift, zoom, shear) |
| **Training Data** | Cá»‘ Ä‘á»‹nh | Thay Ä‘á»•i má»—i epoch |
| **Epochs** | 15-20 | 30 |
| **Generator** | âŒ KhÃ´ng | âœ… `datagen.flow()` |
| **steps_per_epoch** | âŒ KhÃ´ng cáº§n | âœ… `len(x_train) // batch_size` |
| **Flexibility** | âŒ Cá»©ng nháº¯c | âœ… Parameter `use_augmentation` |
| **Real-world Acc** | âŒ Tháº¥p | âœ… **Cao** |

---

## ğŸ“ˆ Training Behavior

### TrÆ°á»›c (KhÃ´ng Augmentation)
```
Epoch 1: train_acc=0.95, val_acc=0.97
Epoch 2: train_acc=0.98, val_acc=0.98
Epoch 3: train_acc=0.99, val_acc=0.98  â† Overfitting báº¯t Ä‘áº§u
...
Epoch 15: train_acc=0.998, val_acc=0.987  â† Model "thuá»™c lÃ²ng" training set
```

**Káº¿t quáº£ trÃªn áº£nh thá»±c táº¿:** âŒ **Dá»± Ä‘oÃ¡n sai!**

---

### Sau (CÃ³ Augmentation)
```
Epoch 1: train_acc=0.85, val_acc=0.95  â† Train acc tháº¥p hÆ¡n val acc (bÃ¬nh thÆ°á»ng!)
Epoch 2: train_acc=0.91, val_acc=0.97
Epoch 3: train_acc=0.93, val_acc=0.98
...
Epoch 30: train_acc=0.97, val_acc=0.99  â† Model há»c tá»‘t, khÃ´ng overfitting
```

**Káº¿t quáº£ trÃªn áº£nh thá»±c táº¿:** âœ… **Dá»± Ä‘oÃ¡n Ä‘Ãºng!**

---

## ğŸ’¡ Táº¡i sao Train Accuracy tháº¥p hÆ¡n Validation Accuracy?

**CÃ¢u tráº£ lá»i:** ÄÃ¢y lÃ  **BÃŒNH THÆ¯á»œNG** khi dÃ¹ng Data Augmentation!

```
Training data:
  áº£nh gá»‘c â†’ augment â†’ xoay, dá»‹ch, zoom, mÃ©o â†’ KHÃ“ HÆ N
  
Validation data:
  áº£nh gá»‘c â†’ KHÃ”NG augment â†’ giá»¯ nguyÃªn â†’ Dá»„ HÆ N
```

â†’ Model pháº£i há»c bÃ i toÃ¡n khÃ³ hÆ¡n khi train, nÃªn train accuracy tháº¥p hÆ¡n.

â†’ NhÆ°ng nhá» Ä‘Ã³, model tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n, dá»± Ä‘oÃ¡n áº£nh thá»±c táº¿ chÃ­nh xÃ¡c hÆ¡n!

---

## ğŸš€ Migration Guide

### Náº¿u báº¡n Ä‘ang dÃ¹ng code cÅ©:

**Option 1: DÃ¹ng Google Colab (Khuyáº¿n nghá»‹)**
1. Upload `colab_training.ipynb` lÃªn Colab
2. Cháº¡y táº¥t cáº£ cells
3. Download model má»›i

**Option 2: Update code local**
1. Pull code má»›i tá»« git
2. Cháº¡y `python train_all.py` hoáº·c `python src/train_mnist.py`
3. Chá» training hoÃ n thÃ nh

**Option 3: Chá»‰ thay model file**
1. Download model Ä‘Ã£ train sáºµn (náº¿u cÃ³)
2. Replace `models/mnist_model.h5`
3. Done!

---

## ğŸ‰ Tá»•ng káº¿t

### Code cÅ©:
```python
model.fit(x_train, y_train, epochs=15)
```
â†’ âŒ Há»c thuá»™c lÃ²ng MNIST, fail trÃªn áº£nh thá»±c táº¿

### Code má»›i:
```python
datagen = ImageDataGenerator(rotation, shift, zoom, shear)
model.fit(datagen.flow(x_train, y_train), epochs=30)
```
â†’ âœ… Há»c tá»•ng quÃ¡t, **thÃ nh cÃ´ng trÃªn áº£nh thá»±c táº¿!**

---

**Giá» Ä‘Ã¢y, model cá»§a báº¡n khÃ´ng cÃ²n lÃ  "sinh viÃªn há»c váº¹t" mÃ  lÃ  "sinh viÃªn thÃ´ng minh" biáº¿t Ã¡p dá»¥ng kiáº¿n thá»©c vÃ o thá»±c táº¿! ğŸ“**

---

*Táº¡o bá»Ÿi: AI Assistant*  
*NgÃ y: 2025-11-14*

