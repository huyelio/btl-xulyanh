"""
Google Colab Script Ä‘á»ƒ Huáº¥n luyá»‡n Model Chinese MNIST
HÆ°á»›ng dáº«n sá»­ dá»¥ng:
1. Táº¡o má»™t notebook má»›i trÃªn Google Colab
2. Copy toÃ n bá»™ code nÃ y vÃ o má»™t cell
3. Cháº¡y cell vÃ  lÃ m theo hÆ°á»›ng dáº«n
4. File chinese_model.h5 sáº½ Ä‘Æ°á»£c tá»± Ä‘á»™ng táº£i vá» mÃ¡y
"""

# ========== CELL 1: SETUP VÃ€ Táº¢I Dá»® LIá»†U ==========
print("=" * 60)
print("BÆ¯á»šC 1: CÃ€I Äáº¶T MÃ”I TRÆ¯á»œNG VÃ€ Táº¢I Dá»® LIá»†U")
print("=" * 60)

# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
import os
import zipfile

print("\nâœ“ ÄÃ£ import thÆ° viá»‡n")
print(f"TensorFlow version: {tf.__version__}")

# Kiá»ƒm tra GPU
print(f"\nGPU available: {tf.config.list_physical_devices('GPU')}")

# ========== PHÆ¯Æ NG ÃN 1: Sá»¬ Dá»¤NG KAGGLE API ==========
print("\n" + "=" * 60)
print("CÃ€I Äáº¶T KAGGLE API")
print("=" * 60)
print("\nHÆ¯á»šNG DáºªN:")
print("1. Truy cáº­p: https://www.kaggle.com/settings/account")
print("2. Scroll xuá»‘ng pháº§n 'API', click 'Create New Token'")
print("3. File kaggle.json sáº½ Ä‘Æ°á»£c táº£i vá»")
print("4. Upload file kaggle.json vÃ o Colab báº±ng Files panel (bÃªn trÃ¡i)")
print("\nSau khi upload, cháº¡y tiáº¿p Ä‘á»ƒ cÃ i Ä‘áº·t...")

# Upload kaggle.json
from google.colab import files
print("\nğŸ“¤ Vui lÃ²ng upload file kaggle.json:")
uploaded = files.upload()

# CÃ i Ä‘áº·t Kaggle
!pip install -q kaggle

# Di chuyá»ƒn kaggle.json vÃ o Ä‘Ãºng thÆ° má»¥c
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

print("\nâœ“ ÄÃ£ cÃ i Ä‘áº·t Kaggle API")

# Táº£i dataset Chinese MNIST
print("\n" + "=" * 60)
print("ÄANG Táº¢I DATASET CHINESE MNIST...")
print("=" * 60)

!kaggle datasets download -d gpreda/chinese-mnist

print("\nâœ“ ÄÃ£ táº£i xong dataset")

# Giáº£i nÃ©n file
print("\nğŸ“¦ Äang giáº£i nÃ©n...")
with zipfile.ZipFile('chinese-mnist.zip', 'r') as zip_ref:
    zip_ref.extractall('chinese_mnist_data')

print("âœ“ ÄÃ£ giáº£i nÃ©n xong")

# Kiá»ƒm tra files
print("\nğŸ“ Files trong dataset:")
!ls -lh chinese_mnist_data/

# ========== BÆ¯á»šC 2: Äá»ŒC VÃ€ CHUáº¨N Bá»Š Dá»® LIá»†U ==========
print("\n" + "=" * 60)
print("BÆ¯á»šC 2: Äá»ŒC VÃ€ CHUáº¨N Bá»Š Dá»® LIá»†U")
print("=" * 60)

# Äá»c CSV file
csv_path = 'chinese_mnist_data/chinese_mnist.csv'
print(f"\nğŸ“– Äang Ä‘á»c file: {csv_path}")
df = pd.read_csv(csv_path)

print(f"\nâœ“ ÄÃ£ Ä‘á»c xong. Shape: {df.shape}")
print(f"\nCÃ¡c cá»™t trong dataset:")
print(df.columns.tolist())
print(f"\nMáº«u dá»¯ liá»‡u Ä‘áº§u tiÃªn:")
print(df.head())

# PhÃ¢n tÃ­ch labels
print(f"\nğŸ“Š PhÃ¢n bá»‘ labels:")
print(df['character'].value_counts().sort_index())
print(f"\nSá»‘ lÆ°á»£ng labels khÃ¡c nhau: {df['character'].nunique()}")

# TÃ¡ch X (áº£nh) vÃ  y (labels)
print("\n" + "=" * 60)
print("CHUáº¨N Bá»Š Dá»® LIá»†U HUáº¤N LUYá»†N")
print("=" * 60)

# Dataset Chinese MNIST cÃ³ cÃ¡c cá»™t: suite_id, sample_id, code, value, character, vÃ  cÃ¡c pixel
# CÃ¡c pixel columns lÃ  tá»« 'pixel1' Ä‘áº¿n 'pixel4096' (64x64 = 4096)
pixel_columns = [col for col in df.columns if col.startswith('pixel')]
print(f"\nâœ“ TÃ¬m tháº¥y {len(pixel_columns)} pixel columns")

# TÃ¡ch features (X) vÃ  labels (y)
X = df[pixel_columns].values
y = df['code'].values  # 'code' lÃ  nhÃ£n sá»‘ tá»« 1-15

print(f"\nShape cá»§a X: {X.shape}")
print(f"Shape cá»§a y: {y.shape}")
print(f"GiÃ¡ trá»‹ y: tá»« {y.min()} Ä‘áº¿n {y.max()}")

# Chuyá»ƒn labels vá» 0-indexed (tá»« 0-14 thay vÃ¬ 1-15)
y = y - 1
print(f"âœ“ ÄÃ£ chuyá»ƒn labels vá» 0-indexed: tá»« {y.min()} Ä‘áº¿n {y.max()}")

# Reshape áº£nh vá» (N, 64, 64, 1)
print("\nğŸ”„ Reshape áº£nh...")
X = X.reshape(-1, 64, 64, 1)
print(f"âœ“ Shape sau reshape: {X.shape}")

# Chuáº©n hÃ³a vá» [0, 1]
print("\nğŸ“ Chuáº©n hÃ³a pixel values...")
X = X.astype('float32') / 255.0
print(f"âœ“ Pixel range: [{X.min():.3f}, {X.max():.3f}]")

# Chuyá»ƒn labels sang categorical (one-hot encoding)
print("\nğŸ”¢ Chuyá»ƒn labels sang categorical...")
y_categorical = keras.utils.to_categorical(y, num_classes=15)
print(f"âœ“ Shape cá»§a y_categorical: {y_categorical.shape}")

# Chia train/validation
print("\nâœ‚ï¸ Chia dá»¯ liá»‡u train/validation...")
X_train, X_val, y_train, y_val = train_test_split(
    X, y_categorical, 
    test_size=0.2, 
    random_state=42,
    stratify=y
)

print(f"âœ“ Training set: {X_train.shape[0]} samples")
print(f"âœ“ Validation set: {X_val.shape[0]} samples")

# ========== BÆ¯á»šC 3: XÃ‚Y Dá»°NG MODEL ==========
print("\n" + "=" * 60)
print("BÆ¯á»šC 3: XÃ‚Y Dá»°NG MODEL CNN")
print("=" * 60)

model = keras.Sequential([
    # Convolutional Block 1
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    
    # Convolutional Block 2
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    
    # Convolutional Block 3
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    
    # Convolutional Block 4
    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.BatchNormalization(),
    
    # Flatten and Dense layers
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(512, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.2),
    
    # Output layer: 15 classes
    layers.Dense(15, activation='softmax')
])

print("\nâœ“ ÄÃ£ táº¡o model")
print("\nğŸ“‹ Model Summary:")
model.summary()

# ========== BÆ¯á»šC 4: COMPILE MODEL ==========
print("\n" + "=" * 60)
print("BÆ¯á»šC 4: COMPILE MODEL")
print("=" * 60)

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("âœ“ ÄÃ£ compile model vá»›i:")
print("  - Optimizer: Adam")
print("  - Loss: Categorical Crossentropy")
print("  - Metrics: Accuracy")

# ========== BÆ¯á»šC 5: HUáº¤N LUYá»†N ==========
print("\n" + "=" * 60)
print("BÆ¯á»šC 5: HUáº¤N LUYá»†N MODEL")
print("=" * 60)

# Callbacks
early_stopping = keras.callbacks.EarlyStopping(
    monitor='val_accuracy',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-7,
    verbose=1
)

print("\nğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n...")
print("LÆ°u Ã½: QuÃ¡ trÃ¬nh cÃ³ thá»ƒ máº¥t 10-20 phÃºt tÃ¹y thuá»™c vÃ o GPU\n")

history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=64,
    validation_data=(X_val, y_val),
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

print("\nâœ… ÄÃƒ HOÃ€N THÃ€NH HUáº¤N LUYá»†N!")

# ========== BÆ¯á»šC 6: ÄÃNH GIÃ ==========
print("\n" + "=" * 60)
print("BÆ¯á»šC 6: ÄÃNH GIÃ MODEL")
print("=" * 60)

# ÄÃ¡nh giÃ¡ trÃªn validation set
val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
print(f"\nğŸ“Š Káº¿t quáº£ trÃªn Validation Set:")
print(f"  - Loss: {val_loss:.4f}")
print(f"  - Accuracy: {val_accuracy*100:.2f}%")

# Váº½ biá»ƒu Ä‘á»“ training history
import matplotlib.pyplot as plt

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# Accuracy plot
ax1.plot(history.history['accuracy'], label='Training Accuracy')
ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
ax1.set_title('Model Accuracy')
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy')
ax1.legend()
ax1.grid(True)

# Loss plot
ax2.plot(history.history['loss'], label='Training Loss')
ax2.plot(history.history['val_loss'], label='Validation Loss')
ax2.set_title('Model Loss')
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Loss')
ax2.legend()
ax2.grid(True)

plt.tight_layout()
plt.show()

# ========== BÆ¯á»šC 7: LÆ¯U VÃ€ Táº¢I Vá»€ MODEL ==========
print("\n" + "=" * 60)
print("BÆ¯á»šC 7: LÆ¯U VÃ€ Táº¢I MODEL Vá»€ MÃY")
print("=" * 60)

# LÆ°u model
model_filename = 'chinese_model.h5'
print(f"\nğŸ’¾ Äang lÆ°u model: {model_filename}")
model.save(model_filename)
print("âœ“ ÄÃ£ lÆ°u model")

# Kiá»ƒm tra file size
file_size = os.path.getsize(model_filename) / (1024 * 1024)  # Convert to MB
print(f"\nğŸ“¦ KÃ­ch thÆ°á»›c file: {file_size:.2f} MB")

# Táº£i vá» mÃ¡y
print("\nğŸ“¥ Tá»± Ä‘á»™ng táº£i file vá» mÃ¡y cá»§a báº¡n...")
files.download(model_filename)

print("\n" + "=" * 60)
print("âœ… HOÃ€N Táº¤T!")
print("=" * 60)
print(f"""
Tá»”NG Káº¾T:
âœ“ Model Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n thÃ nh cÃ´ng
âœ“ Validation Accuracy: {val_accuracy*100:.2f}%
âœ“ File {model_filename} Ä‘Ã£ Ä‘Æ°á»£c táº£i vá» mÃ¡y
âœ“ Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng file nÃ y trong app.py

BÆ¯á»šC TIáº¾P THEO:
1. Di chuyá»ƒn file {model_filename} vÃ o thÆ° má»¥c: btl_final/models/
2. Cháº¡y file app.py Ä‘á»ƒ sá»­ dá»¥ng model

LABELS MAPPING:
0: é›¶ (zero)      5: äº” (five)       10: å (ten)
1: ä¸€ (one)       6: å…­ (six)        11: ç™¾ (hundred)
2: äºŒ (two)       7: ä¸ƒ (seven)      12: åƒ (thousand)
3: ä¸‰ (three)     8: å…« (eight)      13: ä¸‡ (ten thousand)
4: å›› (four)      9: ä¹ (nine)       14: äº¿ (hundred million)
""")

